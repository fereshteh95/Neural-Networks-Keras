{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SAME\\Msc\\5th semester\\ANN and deep learning\\HWs\\HW2\n"
     ]
    }
   ],
   "source": [
    "%cd D:/SAME/Msc/5th semester/ANN and deep learning/HWs/HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 28*28    #feature space dimension \n",
    "x_train = x_train.reshape((60000, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = len(x_train)\n",
    "N_test = len(x_test)\n",
    "\n",
    "x_test = x_test.reshape((N_test, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train/225\n",
    "x_test_scaled = x_test/225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_dim=n, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "adam = optimizers.adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train_onehot = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_test_onehot = keras.utils.np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      " - 22s - loss: 0.3231 - val_loss: 0.2592\n",
      "Epoch 2/30\n",
      " - 19s - loss: 0.2162 - val_loss: 0.2084\n",
      "Epoch 3/30\n",
      " - 19s - loss: 0.1915 - val_loss: 0.1815\n",
      "Epoch 4/30\n",
      " - 20s - loss: 0.1678 - val_loss: 0.2317\n",
      "Epoch 5/30\n",
      " - 19s - loss: 0.1629 - val_loss: 0.1896\n",
      "Epoch 6/30\n",
      " - 19s - loss: 0.1476 - val_loss: 0.2428\n",
      "Epoch 7/30\n",
      " - 20s - loss: 0.1544 - val_loss: 0.1954\n",
      "Epoch 8/30\n",
      " - 20s - loss: 0.1415 - val_loss: 0.1857\n",
      "Epoch 9/30\n",
      " - 19s - loss: 0.1379 - val_loss: 0.2056\n",
      "Epoch 10/30\n",
      " - 20s - loss: 0.1275 - val_loss: 0.1778\n",
      "Epoch 11/30\n",
      " - 20s - loss: 0.1256 - val_loss: 0.1741\n",
      "Epoch 12/30\n",
      " - 19s - loss: 0.1321 - val_loss: 0.2020\n",
      "Epoch 13/30\n",
      " - 19s - loss: 0.1440 - val_loss: 0.1738\n",
      "Epoch 14/30\n",
      " - 20s - loss: 0.1267 - val_loss: 0.2097\n",
      "Epoch 15/30\n",
      " - 19s - loss: 0.1180 - val_loss: 0.2287\n",
      "Epoch 16/30\n",
      " - 19s - loss: 0.1384 - val_loss: 0.2605\n",
      "Epoch 17/30\n",
      " - 19s - loss: 0.1358 - val_loss: 0.2473\n",
      "Epoch 18/30\n",
      " - 21s - loss: 0.1261 - val_loss: 0.3200\n",
      "Epoch 19/30\n",
      " - 19s - loss: 0.1578 - val_loss: 0.2660\n",
      "Epoch 20/30\n",
      " - 19s - loss: 0.1439 - val_loss: 0.2906\n",
      "Epoch 21/30\n",
      " - 20s - loss: 0.1459 - val_loss: 0.2320\n",
      "Epoch 22/30\n",
      " - 20s - loss: 0.1503 - val_loss: 0.2454\n",
      "Epoch 23/30\n",
      " - 19s - loss: 0.1440 - val_loss: 0.2573\n",
      "Epoch 24/30\n",
      " - 19s - loss: 0.1585 - val_loss: 0.2529\n",
      "Epoch 25/30\n",
      " - 20s - loss: 0.1580 - val_loss: 0.2894\n",
      "Epoch 26/30\n",
      " - 19s - loss: 0.1527 - val_loss: 0.2678\n",
      "Epoch 27/30\n",
      " - 19s - loss: 0.1649 - val_loss: 0.2878\n",
      "Epoch 28/30\n",
      " - 20s - loss: 0.1500 - val_loss: 0.2698\n",
      "Epoch 29/30\n",
      " - 19s - loss: 0.1701 - val_loss: 0.3079\n",
      "Epoch 30/30\n",
      " - 19s - loss: 0.1517 - val_loss: 0.2682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x188c5a754e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled,\n",
    "          y_train_onehot,\n",
    "          batch_size=32,\n",
    "          epochs=30, shuffle=True,\n",
    "          validation_data=(x_test_scaled, y_test_onehot),\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_one = np.zeros((10000,1))\n",
    "for i in range(len(predicted_y_one)):\n",
    "    predicted_y_one[i] = list(predicted_y[i][:]).index(predicted_y[i][:].max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.37\n",
      "\n",
      "9537\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range(len(predicted_y_one)):\n",
    "    if predicted_y_one[i] == y_test[i]:\n",
    "        acc += 1\n",
    "    \n",
    "test_acc = ((acc)/len(y_test))*100\n",
    "print(test_acc)\n",
    "print()\n",
    "print((acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
